import torch
import os
import tempfile
import torchaudio
import json
import numpy as np
import random
import gc
# å¼•å…¥ ComfyUI çš„å·¥å…·ä»¥æ”¯æŒè¿›åº¦æ¡
from comfy.utils import ProgressBar

# ä» utils_asr å¯¼å…¥
from .utils_asr import load_asr_model, unload_asr_model

# ================= é…ç½®ä¸å¸¸é‡ =================

ASR_LANGUAGES = {
    "è‡ªåŠ¨è¯†åˆ« (Auto)": None,
    "ä¸­æ–‡ (Chinese)": "Chinese",
    "è‹±è¯­ (English)": "English",
    "ç²¤è¯­ (Cantonese)": "Cantonese",
    "æ—¥è¯­ (Japanese)": "Japanese",
    "éŸ©è¯­ (Korean)": "Korean",
    "æ³•è¯­ (French)": "French",
    "å¾·è¯­ (German)": "German",
    "è¥¿ç­ç‰™è¯­ (Spanish)": "Spanish",
    "ä¿„è¯­ (Russian)": "Russian",
    "æ„å¤§åˆ©è¯­ (Italian)": "Italian",
    "è‘¡è„ç‰™è¯­ (Portuguese)": "Portuguese",
    "æ³°è¯­ (Thai)": "Thai",
    "è¶Šå—è¯­ (Vietnamese)": "Vietnamese",
    "é˜¿æ‹‰ä¼¯è¯­ (Arabic)": "Arabic",
    "å°å°¼è¯­ (Indonesian)": "Indonesian",
    "åœŸè€³å…¶è¯­ (Turkish)": "Turkish",
    "å°åœ°è¯­ (Hindi)": "Hindi",
    "é©¬æ¥è¯­ (Malay)": "Malay",
    "è·å…°è¯­ (Dutch)": "Dutch",
    "ç‘å…¸è¯­ (Swedish)": "Swedish",
    "ä¸¹éº¦è¯­ (Danish)": "Danish",
    "èŠ¬å…°è¯­ (Finnish)": "Finnish",
    "æ³¢å…°è¯­ (Polish)": "Polish",
    "æ·å…‹è¯­ (Czech)": "Czech",
    "è²å¾‹å®¾è¯­ (Filipino)": "Filipino",
    "æ³¢æ–¯è¯­ (Persian)": "Persian",
    "å¸Œè…Šè¯­ (Greek)": "Greek",
    "åŒˆç‰™åˆ©è¯­ (Hungarian)": "Hungarian",
    "é©¬å…¶é¡¿è¯­ (Macedonian)": "Macedonian",
    "ç½—é©¬å°¼äºšè¯­ (Romanian)": "Romanian"
}

# ================= è¾…åŠ©å‡½æ•° =================

def save_audio_to_temp(audio_input):
    """
    å°† ComfyUI çš„éŸ³é¢‘ Tensor ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶ã€‚
    """
    try:
        waveform = audio_input['waveform'] 
        sample_rate = audio_input['sample_rate']
        
        # å¤„ç†ç»´åº¦
        if waveform.dim() == 3:
            wav_tensor = waveform[0]
        else:
            wav_tensor = waveform

        if wav_tensor.shape[0] > wav_tensor.shape[1]: 
             wav_tensor = wav_tensor.t()

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        temp_file.close()
        
        torchaudio.save(temp_file.name, wav_tensor.cpu(), sample_rate)
        return temp_file.name
    except Exception as e:
        print(f"[ASR Error] Failed to save temp audio: {e}")
        return None

# ================= èŠ‚ç‚¹ 1: æ ‡å‡† ASR èŠ‚ç‚¹ (å·²ç²¾ç®€è¾“å‡º) =================

class Qwen_ASR_Node:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    @classmethod
    def INPUT_TYPES(cls):
        presets = ["Qwen3-ASR-1.7B", "Qwen3-ASR-0.6B"]
        return {
            "required": {
                "éŸ³é¢‘": ("AUDIO", ),
                "æ¨¡å‹åç§°": (presets, {"default": presets[0]}),
                "è¯­è¨€": (list(ASR_LANGUAGES.keys()), {"default": "è‡ªåŠ¨è¯†åˆ« (Auto)"}),
                "æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "placeholder": "å¯é€‰ï¼šè¾“å…¥ä¸Šä¸‹æ–‡æˆ–æç¤ºè¯"}),
                "ç”Ÿæˆæ—¶é—´æˆ³": ("BOOLEAN", {"default": False, "label": "ç”Ÿæˆæ—¶é—´æˆ³ (ä»…å†…éƒ¨è®¡ç®—, æš‚ä¸è¾“å‡º)"}),
                "ä¸‹è½½æº": (["ModelScope", "HuggingFace", "HF Mirror"], {"default": "ModelScope"}),
                "è‡ªåŠ¨ä¸‹è½½æ¨¡å‹": ("BOOLEAN", {"default": False}),
            }
        }

    # ä¿®æ”¹ï¼šåªè¾“å‡ºä¸€ä¸ª STRING
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("æ–‡æœ¬è¾“å‡º",)
    FUNCTION = "transcribe_audio"
    CATEGORY = "ğŸ’¬ AIäººå·¥æ™ºèƒ½/éŸ³é¢‘"
    DESCRIPTION = "ä½¿ç”¨ Qwen3-ASR è¿›è¡Œè¯­éŸ³è¯†åˆ«ã€‚"

    def transcribe_audio(self, éŸ³é¢‘, æ¨¡å‹åç§°, è¯­è¨€, æç¤ºè¯, ç”Ÿæˆæ—¶é—´æˆ³, ä¸‹è½½æº, è‡ªåŠ¨ä¸‹è½½æ¨¡å‹):
        
        temp_wav_path = None
        try:
            # 1. å‡†å¤‡éŸ³é¢‘
            temp_wav_path = save_audio_to_temp(éŸ³é¢‘)
            if not temp_wav_path:
                raise ValueError("Audio processing failed.")

            # 2. åŠ è½½æ¨¡å‹
            model = load_asr_model(
                æ¨¡å‹åç§°, 
                self.device, 
                è‡ªåŠ¨ä¸‹è½½æ¨¡å‹, 
                source=ä¸‹è½½æº, 
                use_aligner=ç”Ÿæˆæ—¶é—´æˆ³
            )

            # 3. å‡†å¤‡å‚æ•°
            target_lang = ASR_LANGUAGES.get(è¯­è¨€, None)
            context_prompt = æç¤ºè¯.strip() if æç¤ºè¯.strip() else None

            print(f"[Qwen ASR] Transcribing... Lang: {target_lang if target_lang else 'Auto'}")
            
            # 4. æ‰§è¡Œæ¨ç†
            kwargs = {
                "audio": [temp_wav_path],
                "language": [target_lang] if target_lang else None,
                "return_time_stamps": ç”Ÿæˆæ—¶é—´æˆ³
            }
            if context_prompt:
                kwargs["context"] = [context_prompt]

            results = model.transcribe(**kwargs)

            # 5. å¤„ç†ç»“æœ
            result = results[0]
            text_output = result.text
            
            print(f"[Qwen ASR] Detected: {result.language}")
            print(f"[Qwen ASR] Text: {text_output[:50]}...")

            # åªè¿”å›æ–‡æœ¬
            return (text_output,)

        except Exception as e:
            import traceback
            traceback.print_exc()
            raise Exception(f"ASR Error: {str(e)}")
            
        finally:
            if temp_wav_path and os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)

# ================= èŠ‚ç‚¹ 2: æ‰¹é‡ ASR èŠ‚ç‚¹ (å·²ç²¾ç®€è¾“å‡º) =================

class Qwen_ASR_Batch_Node:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    @classmethod
    def INPUT_TYPES(cls):
        presets = ["Qwen3-ASR-1.7B", "Qwen3-ASR-0.6B"]
        return {
            "required": {
                "éŸ³é¢‘åˆ—è¡¨": ("AUDIO", ), 
                "æ¨¡å‹åç§°": (presets, {"default": presets[0]}),
                "è¯­è¨€": (list(ASR_LANGUAGES.keys()), {"default": "è‡ªåŠ¨è¯†åˆ« (Auto)"}),
                "æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "placeholder": "æ‰¹é‡æç¤ºè¯"}),
                "ç”Ÿæˆæ—¶é—´æˆ³": ("BOOLEAN", {"default": False}),
                "ä¸‹è½½æº": (["ModelScope", "HuggingFace", "HF Mirror"], {"default": "ModelScope"}),
                "è‡ªåŠ¨ä¸‹è½½æ¨¡å‹": ("BOOLEAN", {"default": False}),
            }
        }

    # ä¿®æ”¹ï¼šåªè¾“å‡ºä¸€ä¸ª STRING
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("åˆå¹¶æ–‡æœ¬",)
    FUNCTION = "batch_transcribe"
    CATEGORY = "ğŸ’¬ AIäººå·¥æ™ºèƒ½/éŸ³é¢‘"
    DESCRIPTION = "æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘ç‰‡æ®µï¼Œè¾“å‡ºåˆå¹¶åçš„æ–‡æœ¬ã€‚"

    def batch_transcribe(self, éŸ³é¢‘åˆ—è¡¨, æ¨¡å‹åç§°, è¯­è¨€, æç¤ºè¯, ç”Ÿæˆæ—¶é—´æˆ³, ä¸‹è½½æº, è‡ªåŠ¨ä¸‹è½½æ¨¡å‹):
        temp_files = []
        try:
            audio_inputs = []
            if isinstance(éŸ³é¢‘åˆ—è¡¨, list):
                audio_inputs = éŸ³é¢‘åˆ—è¡¨
            else:
                audio_inputs = [éŸ³é¢‘åˆ—è¡¨]

            total_files = len(audio_inputs)
            if total_files == 0:
                return ("",)

            # è¿›åº¦æ¡
            pbar = ProgressBar(total_files)

            model = load_asr_model(
                æ¨¡å‹åç§°, 
                self.device, 
                è‡ªåŠ¨ä¸‹è½½æ¨¡å‹, 
                source=ä¸‹è½½æº, 
                use_aligner=ç”Ÿæˆæ—¶é—´æˆ³
            )
            
            target_lang = ASR_LANGUAGES.get(è¯­è¨€, None)
            context_prompt = æç¤ºè¯.strip() if æç¤ºè¯.strip() else None
            
            full_text_list = []

            print(f"[Qwen ASR Batch] Processing {total_files} files...")

            for i, audio_item in enumerate(audio_inputs):
                temp_path = None
                try:
                    temp_path = save_audio_to_temp(audio_item)
                    if not temp_path:
                        continue
                    
                    kwargs = {
                        "audio": [temp_path],
                        "language": [target_lang] if target_lang else None,
                        "return_time_stamps": ç”Ÿæˆæ—¶é—´æˆ³
                    }
                    if context_prompt:
                        kwargs["context"] = [context_prompt]

                    results = model.transcribe(**kwargs)
                    res = results[0]

                    # æ”¶é›†ç»“æœ
                    full_text_list.append(res.text)

                except Exception as inner_e:
                    print(f"[Error] Batch processing failed at index {i}: {inner_e}")
                    full_text_list.append(f"[Error in file {i+1}]")
                
                finally:
                    if temp_path and os.path.exists(temp_path):
                        os.remove(temp_path)
                    pbar.update(1)

            # åªè¿”å›åˆå¹¶åçš„æ–‡æœ¬
            return ("\n".join(full_text_list),)

        except Exception as e:
            import traceback
            traceback.print_exc()
            raise Exception(f"Batch ASR Error: {str(e)}")
        finally:
            unload_asr_model()
